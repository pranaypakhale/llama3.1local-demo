# llama3.1local-demo

1. install ollama
2. install all requirements.txt dependencies
3. run on terminal "ollama pull llama 3.1"
4. run app.py script- "stremlit run app.py"
5. ask question in the application
   
